## Modules

There are three custom modules in the setup, `airflow`, `mlflow`, and `jupyterhub`, each responsible to deploy one specific workflow tool.

### Modules.Airflow

user management
git repo airflow_dag


Two `kubernetes_secret`
(1) `airflow_db_credentials`
(2) `airflow_https_git_secret`

`rds-airflow` calles the rds module in the infrastructure directory to create an rds database that can will be attached to the airflow server.

Airflow itself is deployed using the helm resource `helm_release`. This allows to deploy a helm chart onto the cluster using from withing a Terraform setup.


```bash
locals {
  k8s_airflow_db_secret_name = "${var.name}-db-auth"
  git_airflow_repo_secret_name = "${var.name}-https-git-secret"
}


resource "kubernetes_secret" "airflow_db_credentials" {
  metadata {
    name      = local.k8s_airflow_db_secret_name
    namespace = helm_release.airflow.namespace
  }
  data = {
    "postgresql-password" = module.rds-airflow.rds_password
  }
}


resource "kubernetes_secret" "airflow_https_git_secret" {
  metadata {
    name      = local.git_airflow_repo_secret_name
    namespace = helm_release.airflow.namespace
  }
  data = {
    "username" = var.git_username
    "password" = var.git_token
  }
}

resource "random_password" "rds_password" {
  length  = 16
  special = true
}


# create rds for airflow
module "rds-airflow" {
  source                      = "../../infrastructure/rds"
  vpc_id                      = var.vpc_id
  private_subnets             = var.private_subnets
  private_subnets_cidr_blocks = var.private_subnets_cidr_blocks
  rds_port                    = var.rds_port
  rds_name                    = var.rds_name
  rds_password                = coalesce(var.rds_password, random_password.rds_password.result)
  rds_engine                  = var.rds_engine
  rds_engine_version          = var.rds_engine_version
  rds_instance_class          = var.rds_instance_class
  storage_type                = var.storage_type
  max_allocated_storage       = var.max_allocated_storage
}



resource "helm_release" "airflow" {
  name             = var.name
  namespace        = var.name
  create_namespace = var.create_namespace

  repository = "https://airflow-helm.github.io/charts" #var.helm_chart_repository
  chart      = var.helm_chart_name
  version    = var.helm_chart_version
  wait       = false # deactivate post install hooks otherwise will fail

  values = [
    "${file("${path.module}/../../applications/airflow/values.yaml")}"
    ]
  
  # set {
  #   name = "externalDatabase.database"
  #   value = "airflow_db"
  # }
  set {
    name  = "externalDatabase.port"
    value = var.rds_port
  }
  set {
    name  = "externalDatabase.host"
    value = module.rds-airflow.rds_host
  }
  set {
    name = "externalDatabase.passwordSecret"
    value = local.k8s_airflow_db_secret_name
  }
  set {
    name  = "dags.gitSync.repo"
    value = var.git_repository_url
  }
  set {
    name  = "dags.gitSync.branch"
    value = var.git_branch
  }
  set {
    name  = "dags.gitSync.httpSecret"
    value = local.git_airflow_repo_secret_name
  }
}

```

### Modules.Mlflow

https://pedro-munoz.tech/how-to-setup-mlflow-in-production/

https://kili-technology.com/data-labeling/machine-learning/how-to-manage-your-machine-learning-pipeline-with-mlflow

open endpoint - not very secure

`aws_s3_bucket`

`rds-mlflow`

`helm_release`

```bash
# create s3 bucket for artifacts
resource "aws_s3_bucket" "mlflow" {
  bucket = var.mlflow_s3_bucket_name
  # tags          = var.tags
  force_destroy = var.s3_force_destroy
}

resource "aws_s3_bucket_server_side_encryption_configuration" "bucket_state_encryption" {
  bucket = aws_s3_bucket.mlflow.bucket
  rule {
    apply_server_side_encryption_by_default {
      sse_algorithm = "AES256"
    }
  }
}

resource "random_password" "rds_password" {
  #count  = var.generate_db_password ? 1 : 0
  length = 16
  # MLFlow has troubles using special characters
  special = false
}

# create rds for s3
module "rds-mlflow" {
  source                      = "../../infrastructure/rds"
  vpc_id                      = var.vpc_id
  private_subnets             = var.private_subnets
  private_subnets_cidr_blocks = var.private_subnets_cidr_blocks
  rds_port                    = var.rds_port
  rds_name                    = var.rds_name
  rds_password                = coalesce(var.rds_password, random_password.rds_password.result)
  rds_engine                  = var.rds_engine
  rds_engine_version          = var.rds_engine_version
  rds_instance_class          = var.rds_instance_class
  storage_type                = var.storage_type
  max_allocated_storage       = var.max_allocated_storage
}


resource "helm_release" "mlflow" {
  name             = var.name
  namespace        = var.name
  create_namespace = var.create_namespace

  chart = "${path.module}/../../applications/mlflow/"
  values = [
    "${file("${path.module}/../../applications/mlflow/values.yaml")}"
    ]
  
  set {
    name  = "RDS_USERNAME"
    value = module.rds-mlflow.rds_username
  }
  set {
    name  = "RDS_PASSWORD"
    value = module.rds-mlflow.rds_password
  }
  set {
    name  = "RDS_HOST"
    value = module.rds-mlflow.rds_host
  }
  set {
    name  = "RDS_PORT"
    value = var.rds_port
  }
  set {
    name  = "ARTIFACT_S3_BUCKET"
    value = var.mlflow_s3_bucket_name
  }
  set {
    name  = "ARTIFACT_S3_KEY_PREFIX"
    value = "test"
  }
  set {
    name  = "DB_NAME"
    value = module.rds-mlflow.rds_dbname
  }
}

```

+ Create a docker image for the MLFlow tracking server.
+ Deploy Postgresql database on Kubernetes.
    + Helm to deploy PostgreSQL
+ Create YAML configurations for deployment, service and configmap to deploy the tracking server to Kubernetes.
    + The first thing we need to do is create the configmap and secrets for the tracking server.



### Modules.Jupyterhub

code-server custom
this is where we need ebs
user management
git repo airflow_dag

`helm_release`

Main settings in value.yaml of helm chart

```bash
# create a database

# configure the Amazon EBS CSI Driver with a IAM Role for Service Accounts for least privileged containers.

resource "helm_release" "jupyterhub" {
  name             = var.name
  namespace        = var.name
  create_namespace = var.create_namespace

  repository = "https://jupyterhub.github.io/helm-chart/"
  chart      = var.helm_chart_name
  version    = var.helm_chart_version

  values = [
    "${file("${path.module}/../../applications/jupyterhub/values.yaml")}"
    ]

  # set {
  #   name  = "singleuser.lifecycleHooks.postStart.exec.command"
  #   value = ["git", "clone", "https://github.com/seblum/Airflow_DAGs.git"]
  #   type = list
  # }

}

```
