# Kubernetes

**What is Kubernetes?**

Kubernetes (short: K8s) is greek and means pilot. K8s is an applications orchestrator that originated from Google and is open source. Beeing an application orchestrator, K8s deploys and manages application containers. It scales up and down the respecive containers as needed and allows for zero downtime as well as the possibility of rollbacks. Thus, the meaning of *pilot* relates to its functionining in piloting containers.


## Nodes 

A K8s Cluster usually consistes of a set of nodes. A Node can hereby be a virtual machine (VM) in the cloud, e.g. AWS, Azure, or GCP, or a node can also be of course a physical on-premise instance. In managing containers, K8s distinguishes the nodes between a *master node* and *worker nodes*. The master node is basically the brain of the cluster. This is where everything is organized, handled, and managed. In comparison, a worker nodes is where the heavy lifting is happening, such as running application. Both, master and worker nodes communicate with each other via the so called kubelet. One cluster has only one master node and usually multiple worker nodes.

<!---
The smallets unit for K8s ist a Pod, for Docker it is a container.
 --->

### Master & Control Plane

To be able to work as the brain of the cluster, the master node contains a controll plane made of several components, each of which serves a different function.

+ Scheduler
+ Cluster Store
+ API Server
+ Controller Manager
+ Cloud Controller Manager

<!---
Communication with outside using api server
 --->

##### API Server
The api servers serves as the connection between the frontend and the K8s controll plane. All communications, external and interal, go through it. Frontend to Kubernetes Controll Plane. It exposes a restful api on port 443 to allow communication, as well as performes authentication and authorization checks. Whenever we perform something on the K8s cluster, e.g. using a command like `kubectl apply -f <file.yaml>`, we communicate with the api server (what we do here is shown in the section about pods).

##### Cluster store
The cluster store stores the configuration and state of the entire cluster. It is a distributed key-value data store and the single source of truth database of the cluster. As in the example before, whenever we apply a command like `kubectl apply -f <file.yaml>`, the file is stored on the cluster store to store the configuration.

##### Scheduler
The scheduler of the control plane watches for new workloads/pods and assigns them to a node based on several scheduling factors. These factors include whether a node is healthy, whether there are enough resources available, whether the port is available, or according to affinity or anti-affinity rules.

##### Controller manager
The controller manager is a daemon that manages the control loop. This means, the controller manager is basically a controller of other controllers. Each controller watches the api server for changes to their state. Whenever a current state of a controller does not match the desired state, the control manager administers the changes. These controllers are for example replicasets, endpoints, namespace, or service accounts. There is also the cloud controller manager, which is responsible to interact with the underlying cloud infrastructure.

<!---
Node controller
 --->

### Worker Nodes

There worker nodes are the part of the cluster where the heavy lifting happens. Their VMs (or physical machines) often run linux and thus provide a suitable and running environment for each application.

A worker node consists of three main components.

+ Kubelet
+ Container runtime
+ Kube proxy

##### Kubelet
The kubelet is the main agent of a worker node that runs on every single node. It receives pod definitions from the API server and interacts with the container runtime to run containers associated with the corresponding pods. The kubelet also reports node and pod state to the master node.

##### Container runtime
The container runtime is responsible to pull images from container registries, e.g. from DockerHub, or AWS ECR, as well as starting, and stoping containers. The container runtime thus abstracts container management for K8s and runs a Container Runtime Interface (CRI) within.

##### Kube-proxy
The kube-proxy runs on every node via a DaemondSet. It is responsible for network communications by maintaining network rules to allow communication to pods from inside and outside the cluster. If two pods want to talk to each other, the kube-proxy handles their communication. Each node of the cluster gets its own unique IP adress. The kube-proxy handels the local cluster networking as well as routing the network traffic to a load balanced service.


## Pods

A pod is the smallest deployable unit in K8s (In contrast to K8s, the smallest deployable unit for docker are containers.). Therefore, a pod is a running process that runs on a clusters' node. Within a pod, there is always one *main container* representing the application (in whatever language written, e.g. JS, Python, Go). There also may or may not be *init containers*, and/or *side containers*. Init containers are containers that are executed before the main container. Side containers are containers that support the main containers, e.g. a container that acts as a proxy to your main container. There may be volumes specified within a pod, which enables containers to share and store data.

<!--- TODO: insert image --->
![Pod](kubernetes_pod.png) 

The containers running within a pod communicate with each other using localhost and whatever port they expose. The port itself has a unique ip adress, which enables outward communication between pods.

The problem is that a pods does not have a long lifetime (also denoted as ephemeral) and is disposable. This suggests to never create a pod on its own within a K8s cluster and to rather use controllers instead to deploy and maintain a pods lifecycle, e.g. controllers like *Deployments*. In general, managing ressources in K8s is done via an imperative or declarative management.

### Imperative & Declarative Management {-}

Imperative management means managing the pods via a CLI and specifying all necessary parameters using it. It is good for learning, troubleshooting, and experimenting on the cluster. In contrast, the declarative approach uses a yaml file to state all necessary parameters needed for a ressource, and then using the CLI to administer the changes. The declarative approach is reproducible, which means the same configuration can be applied in different environments (prod/dev). This is best practice to use when building a cluster. As stated, this differentiation does not only hold for pods, but for all ressources within a cluster.

#### Imperative Management {-}

```bash
# start a pod by specifying the pods name, 
# the container image to run, and the port exposed
kubectl run <pod-name> --image="<image-name>" --port=80

# run following command to test the pod specified
# It will forward to localhost:8080
kubectl port-forward pod/<pod-name> 8080:80
```

#### Declarative Management / Configuration {-}

Declarative configuration is done using a *yaml* format, which works on key-value pairs.

```yaml
apiVersion: v1
# specify which kind of configuration this is
# lets configure a simple pod
kind: Pod
# metadata will be explained later on in more detail
metadata:
  name: hello-world
  labels:
	name: hello-world
spec:
  # remember: a pod is a selection of one or more containers
  # we could therefore specify multiple containers
  containers:
    # specify the container name
 	- name: hello
  # specify which container image should be pulled
	image: "<image-name>"
  # ressource configurations will be handled later as well
	ressources:
 	  limits:
		memory: "128Mi"
		cpu: "500m"
	# specify the port on which the container should be exposed
  # similar to the imperative approach
  ports:
  	  ContainerPorts: 80
```

Appyl this declarative configuration using the following kubectl command via the CLI.

```bash
kubectl apply -f "file-name.yaml"

# similar to before, run following to test your pod on localhost:8080
kubectl port-forward pod/<pod-name> 8080:80
```

#### Kubectl

One word to interacting with the cluster using the CLI. In general, *kubectl* is used to interact with the K8s cluster. This allows to run and apply pod configurations such as seen before, as well as the already shown port forwarding. We can also inspect the cluster, see what ressources are running on which nodes, see their configurations, and watch their logs. A small selection of commands are shown below.

```bash
# forward the pods to localhost:8080
kubectl port-forward <ressource>/<pod-name> 8080:80

# show all pods currently running in the cluster
kubectl get pods

# delete a specific pod
kubectl delete pods <pod-name>

# show all instances of a specific resource running on the cluster
# (nodes, pods, deployments, statefulsets, etc) 
kubectl get <resource>

# describe and show specific settings of a pods
kubectl describe pod <pod-name>
```


## Deployments

We should never deploy a pod using `kind:Pod`. Pods are ephemeral, so never treat them like pets. They do not heal on their own and if a pod is terminated, it does not restart by themselves. This is dangerous as there should always be one replica running of and application. This demands for a mechanism for the application to self heal and this is exactly where *Deployments* and *ReplicaSets* come in to solve the problem.

In general, Pods should be managed through Deployments. The purpose of a Deployment is to facilitate software deployment. They manage releases of a new application, they provide zero downtime of an application and create a ReplicaSet behind the scenes. K8s will take care of the full deployment process when applying a Deployment, even if we want to make a rolling update to change the version.

#### Replicasets {-}
A ReplicaSet makes sure that a desired number of pods is running. When looking at Pods' name of a Deployment, it usually has a random string attached. This is because a deployment can have multiple replicas and the random suffix ensures a different name after all. The way ReplicaSets work is that they implement a background control loop that checks the desired number of pods are always present on the cluster. We can specify the number of replicas by creating a yaml-file of a Deployment, similar to previous specifications done to a Pod. As a reminder, the Deployment can be applied using the `kubectl apply -f` as well.

```yaml
apiVersion: apps/v1
# specify that we want a deployment
kind: Deployment
metadata:
  name: hello-world
spec:
  # specify number of replicas
  replicas: 3
  selector:
    matchLabels:
      app: hello-world
  template:
    metadata:
      labels:
        app: hello-world
    spec:
      containers:
      - name: hello-world
        image: seblum/k8s-training:flask-v1
        resources:
          limits:
            memory: "128Mi"
            cpu: "500m"
        ports:
        - containerPort: 80
```

#### Rolling updates
A rolling update means that a new version of the application is rolled out. In general, a basic deployments strategy will delete every single pod before it creates a new version. This is very dangerous since there is downtime. The preferred strategy is to perform a rolling update. This ensures keeping traffic to the previous version until the new one is up and running and alternates traffic until the new version is fully healthy. K8s perfoms the update of an application while the application is up and running. For example, when there are two replicasets running, one with version v1 and one with v2, K8s performs the update such that it only scales v1 down when v2 is already up and running and the traffic has been redirected to v2 as well. How do the deployments need to be configured for that?

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: hello-world
spec:
  replicas: 3
  # a few new things have been added here
  revisionHistory: 20
  # specify the deployments strategy
  strategy:
    type: RollingUpdate
    rollingUpdate:
      # only one pod at a time to become unavailable
      # in our case scaling down of v1
      maxUnavailable: 1
      # never have more than one pod above the mentioned replicas
      # with three replicas, there will never be 5 pods running during a rollout
      maxSurge: 1
  selector:
    matchLabels:
      app: hello-world
  template:
    metadata:
      labels:
        app: hello-world
      annotations:
      	# just an annotation the get the version change
      	kubernetes.io/change-cause: "seblum/k8s-training:flask-v2"
    spec:
      containers:
      - name: hello-world
      # only change specification of the image to v2, k8s performs the update itself
        image: seblum/k8s-training:flask-v2
        resources:
          limits:
            memory: "128Mi"
            cpu: "500m"
        ports:
        - containerPort: 80
```

The changes can be applied as well using `kubectl apply -f "file-name.yaml"`. Good to know, K8s is not deleting the replicasets of previous versions. They are still stored on the Cluster Store. The `spec.revisionHistory: <?>` state in the yaml denoted this. The last ten previous versions are stored on default. However, it doesn't really make sense to keep more such for example in the previous yaml where there are the last 20 versions specified. This enables to perform **Rollbacks** to previous versions. To not have discrepancies in a cluster, one should always update using the declarative approach. Below stated are a number of commands that trigger and help with a rollback or with rollouts in general.

```bash
# check the status of the current deployment process
kubectl rollout status deployments <name>

# pause the rollout of the deployment.
kubectl rollout pause

# check the rollout history of a specific deployment
kubectl rollout history deployment <name>

# undo the rollout of a deployment and switch to previous version
kubectl rollout undo deployment <name>

# goes back to a specific revision
# there is a limit of history and k8s only keeps 10 previous versions
kubectl rollout undo deployment <name> --to-revision=
```


## Services

To overall question when deploying an application is how we can access it. Each individual Pod has its own IP address. Thereby, the client can access this Pod via its IP address. Previously, we have made the app available via `kubectl port-forward` by forwarding the Pods' IP to localhost. However, should only be done for testing purposes and is not a reliable and stable way to enable access. Since Pods are ephemeral, the client cannot rely on the ip address alone. For example, if an application is scaled up or down, there will be new IPs associated with each new Pod.

Instead, *Services* should be used. A service is an abstract way to expose an application as a network service. The service can connect access to a pod via an interal reference, so a change of the Pods IP will not interfere with its accessibility. The service itself has a stable IP adress, a stable DNS name, and a stable port. This allows for a reliable and stable connection from the client to the service, which can then direct the traffic to the pod. There are different types of Services.

+ ClusterIP (Default)
+ NodePort
+ ExternalName
+ LoadBalancer

#### ClusterIP 
The ClusterIP is the default K8s service. This service type will be chosen if no specific type is selected. The ClusterIP is used for cluster internal access and does not allow for external communication. If one Pod wants to talk to another Pod inside the cluster, it will use ClusterIP to do so. The service will allow and send traffic to any pod that is healthy.

#### NodePort
The NodePort service allows to open a port simultaneously on all nodes. Its range lies between between 30.000/32.767. If a client wants to communicate with a node of the cluster, the client directly communicates with the node via its IP address. When the request reaches the port of the node, the NodePort service handles the request and forwards it to the specifically marked pod. 

Using a NodePort is beneficial for example of a request is sent to a node without a pod. The NodePort service will then forward the request to a node which has a healthy port running. However, only having one service specified per port is also a disadvantage. Having one ingress and multiple services is more desireable. The point of running K8s in the cloud is to scale up and down and if the NodeIP address changes, then we have a problem.
<!---
**Accessing API with NodePort Service**
ssh into node `minikube ssh`. then `curl localhost:PORT/api/v1/customer`
Check Nodeports in general
 --->

#### LoadBalancer
Loadbalancers are a standard way of exposing applications to the extern, for example the internet. Loadbalancers automatically distribute incoming traffic across multiple targets to balance the load in an equal level. If K8s is running on the cloud, e.g. AWS or GCP, a Network Load Balancer (NLB) is created. The Cloud Controller Manager (remember the Controller Manager of a Node) is resposible to talk to the underlying cloud provier. In Minikube, the external IP to access the application via the LoadBalancer can be exposed using the command `minikube tunnel`. 

<!---
#### default kubernetes service
A K8s Service is automatically created to access K8s with the K8s API. Check the endpoints of the service and the api-service pod within kube-system namespace
 --->

### Exemplary setup of database and frontend microservices

The following example show the deployment and linking of two different deployments. A *frontend-deployment.yaml* that pulls a container running a [Streamlit App](https://streamlit.io/), and a *database-deployment.yaml* that runs a flask application exposing a dictionary as an exemplary and very basic database. The frontend accesses the flask database using a ClusterIP Service linked to the database-deployment. It also exposes an external IP via a Loadbalancer Service, so the streamlit app can be accesses via the browser and without the use of `kubectl port-forward`.

It is possible to show all endpoints of the cluster using
```bash
kubectl get endpoints
```

When looking at the ClusterIP service with `kubectl describe service backendflask` the IP address of the service to exposes, as well as the listed endpoints that connect to the database-deployments are shown. One can compare them to the IPs of the actual deployments - they are the same.

```yaml
# frontend-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 2
  selector:
    matchLabels:
      app: frontend
  template:
    metadata:
      labels:
        app: frontend
    spec:
      containers:
      - name: frontend
        image: seblum/mlops-public:frontend_streamlit
        resources:
          limits:
            memory: "128Mi"
            cpu: "500m"
        # enviroment variable defined in the application and dockerfile
        # value is ip adress of the order
        env:
            # using the ip adress would be a bad idea.
            # use the service ip adress.
            # value: "<order-service-ip-adress>:8081"
            # how to do it should be this.
            # we reference to the order service
          - name: DB_SERVICE
            value: "backendflask"

          - name: PORT
            value: "5001"
        ports:
          # we can actually use the actual ip of the service or
          # use the dns, as done in the example above.
        - containerPort: 8501
# ---
# apiVersion: v1
# kind: Service
# metadata:
#   name: frontend-node
# spec:
#   type: NodePort
#   selector:
#     app: frontend
#   ports:
#   - port: 80
#     targetPort: 8080
#     nodePort: 30000
# ---
# apiVersion: v1
# kind: Service
# metadata:
#   name: frontend
# spec:
#   type: ClusterIP
#   selector:
#     app: frontend
#   ports:
#   - port: 5003
#     targetPort: 8501
```

```yaml
# database-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: backendflask
spec:
  replicas: 2
  selector:
    matchLabels:
      app: backendflask
  template:
    metadata:
      labels:
        app: backendflask
    spec:
      containers:
      - name: backendflask
        image: seblum/mlops-public:backend_flask
        resources:
          limits:
            memory: "128Mi"
            cpu: "500m"
        ports:
        - containerPort: 5000
---
apiVersion: v1
kind: Service
metadata:
  name: backendflask
spec:
  # send traffic to any pod that matches the label
  type: ClusterIP # does not need to be specified
  selector:
    app: backendflask
  ports:
    # port the service is associated with
  - port: 5001
    # port to access targeted by the access
    # in our case has to be the same as in deployment.
    targetPort: 5000
```

```yaml
apiVersion: v1
kind: Service
metadata:
  name: order
spec:
  type: NodePort
  selector:
	name: order
  ports:
	- port: 8081
  	  targetPort: 8081
  	  # optional NodePort Service
  	  # if we dont specify this, we get a randomly allocated port
  	  nodePort: 30001 
``` 


## Labels, Selectors and Annotations

In the previous sections we already made use of labels, selectors, and annotations, e.g. when matching the ClusterIP service to the back-deployments. Labels are a key-value pair that can be attached to objects such as Pods, Deployments, Replicaset, Services, etc. Overall, they are used to organize and select objects. 

Annotations are an unstructured key-value mapping stored with a resource that may be set by external tools to store and retrieve any metadata. In contrast to labels and selectors, annotations are not used for querying purposes. They are used to assist tools and libraries to work with the K8s ressource, for example to pass configuration around between systems, or to send values so external tools can perform more informed decisions based on the annotations provided.
<!---
Check annotations
 --->

Selectors are used to filter K8s objects based on a set of labels. A selector basically simply uses a boolean language to select pods. The selector matches the labels under a an all or nothing principle, meaning everything specified in the selector must be fulfilled by the labels. However, this works not the other way around. If there are multiple labels specified and the selector matches only one of them, the selector will match the ressource itself. How a selector matches the labels can be tested using the `kubectl` commands as seen below.

```bash
# Show all pods including their labels
kubectl get pods --show-labels

# Show only pods that match the specified selector key-value pairs
kubectl get pods --selector="key=value"
kubectl get pods --selector="key=value,key2=value2"

# in short one can also write
kubectl get pods -l key=value
# or also look for multiple
kubectl get pods -l 'key in (value1, value2)'
```

When using ReplicaSets in a Deployment, their selector matches the labels to a specific pod (check e.g. the section describing Deployments). Any Pods matching the label of the selector will be created according to the specified replicas. Of course, there can also be multiple labels specified.
The same principle accounts when working with Services. Below example shows two different Pods and two NodePort services. Each service matches to a Pod based on their selector-label relationship. Have a look at their specific settings using `kubectl`. The Nodeport Service *labels-and-selectors-2* has no endpoints, as it is all or none and none of the created Pods matches the label `environment=service`. In contrast, even though the Pod *blue* has multiple labels specified, the NodePort Service is linked to it.

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: blue
  labels:
    app: blue
    version: two
  annotations:
	kubernetes.io/change-cause: "seblum/kubernetes:hello-world"
spec:
  containers:
  - name: blue
    image: "seblum/kubernetes:blue"
	resources:
  	  limits:
  		memory: "128Mi"
  		cpu: 	"500m"
---
apiVersion: v1
kind: Pod
metadata:
  name: green
  labels:
    app: blue    
spec:
  containers:
	- name: green
  	  image: "seblum/kubernetes:green"
	  resources:
    	limits:
	 	  memory: "128Mi"
  		  cpu: 	"500m"
---
apiVersion: v1
kind: Service
metadata:
  name: labels-and-selectors
spec:
  type: NodePort
  selector:
	name: blue
  ports:
	- port: 80
  	  targetPort: 8080
---
apiVersion: v1
kind: Service
metadata:
  name: labels-and-selectors-2
spec:
  type: NodePort
  selector:
	name: blue
	environment: service
  ports:
	- port: 80
	  targetPort: 8081
```


## Namespaces

Namespaces allow to organize resources in the cluster, which makes it more overseeable when there are multiple resources for different needs. Maybe we want to organize by team, department, or according to a development environment (dev/prod), etc. By default, K8s will use the *default*-namespace for resources that have not been specified otherwise. Similarly, kubectl interacts with the default namespace as well. Yet, there are already different namespace in a basic K8s cluster

+ **default** - The default namespace for objects with no other namespace
+ **kube-system** - The namespace for objects created by the Kubernetes system
+ **kube-public** - This namespace is created automatically and is readable by all users (including those not authenticated). This namespace is mostly reserved for cluster usage, in case that some resources should be visible and readable publicly throughout the whole cluster. The public aspect of this namespace is only a convention, not a requirement.
+ *kube-node-lease* - This namespace for the lease objects associated with each node which improves the performance of the node heartbeats as the cluster scales.

Of course, there is also the possibility of creating ones own namespace and using it by attaching a e.g. Deployment to it, such as seen in the following example.

```yaml
apiVersion: v1
kind: Namespace
metadata:
  name: monitoring
---
apiVersion: v1
kind: Deployment
metadata:
  name: monitoring-deployment
  namespace: monitoring
spec:
  containers:
  - name: 
    image: "grafana"
  resources:
      limits:
      memory: "128Mi"
      cpu:  "500m"
```

<!---
Cross communication and network policies between namespaces 
develoment namespace and customer svc
demo namespace and customer svc
calling from demo to dev, we call customer.dev
However, we do not usually want them to talk to each other. https://kubernetes.io/docs/concepts/services-networking/network-policies/
 --->


## Service Discovery

Service Discovery is a mechanism that lets applications and microservices locate each other on a network. In fact, we have aready used Service Discovery in the previous sections, they just haven't been mentioned yet. If a client wants to communicate with the application, it should not use the IP of an individual Pod should not use the individual pod ip. Instead, we should rely on services as they have a stable IP address. We have already seen this in the section about Services. Yet, each pod has also an individual DNS (Domain Name System). A DNS translates a domain names to an IP address, just one lookes up a number in a telephone book, so it's much easier to reference to a resource online. This is where service Discovery enters the game.

<!--- TODO: insert image --->
![Service Discovery](kubernetes_service-discovery.png) 

Whenever a service is created, it is registered in the service registry with the service name and the service IP. Most clusters use CoreDNS as a service registry (this would be the telephone book itself). When having a look at the minikube cluster one should see are *core-dns* service running. Now you know what it is for. Having a closer look using `kubectl describe svc <name>`, the core-dns service has only one endpoint. If you want to have an even closer look, you can dive into a pod itself and check the file /etc/resolv.conf. There you find a nameserver <IP> where the IP is the one of the core-dns. 

```bash
# when querying services, it necessary 
# to specify the corresponding namespace
kubectl get service -n kube-system

# command for queriying the dns  
nslookup <podname>
```

#### kube-proxy

As mentioned earlier, each node has three main components: Kubelet, Container Runtime, and the Kube-Proxy. *Kube-Proxy* is a network proxy running on each node and is responsible for internal network communications as well as external.

It also implements a controller that watches the API server for new services and endpoints. Whenever there is a new service or endpoint, the kube-proxy creates a local IPVS rule (IP Virtual Server) that tells the node to intercept traffic destined to the ClusterIP Service. IPVS is built on top of the network filter and implements a transport-layer load balancing. This gives the ability to load balance to real service as well as redirecting traffic to pods that match service label selectors.

This means, kube-proxy is intercepting all the requests and makes sure that when a request to the ClusterIP service is sent using endpoints, the request is forwarded to the healthy pods behind the endpoint. 

<!--- TODO: possibly insert a graph for this --->


## Volume & Storage

Since Pods are ephemeral, any data associated is deleted when a Pod or container restarts. Applications are run stateless the majority of the times, meaning the data does not needs to be kept on the node and the data is stored on an external database. However, there are times when the data wants to be kept, shared between Pods, or when it should persist on the host file system (disk). As described in the section about Pods, a Pod can contain volumes. Volumes are exactly what is needed for such tasks. They are used to store and access data which can be persistent or long lived on K8s.

There are different types of volumes, e.g.:

+ EmptyDir
+ HostPath Volume
+ awsElasticBlockStore: AWS EBS volumes are persistent and originally unmounted. They are read-write-once-only tough.
+ There are multiple other types of volumes, a full list can be found here: https://kubernetes.io/docs/concepts/storage/volumes/#volume-types

#### EmptyDir Volume
An EmptyDir Volume is initially empty (as the name suggests). The volume is a temporary directory that shares the pods lifetime. If the pod dies, the contents of the emptyDir are lost as well. The EmptyDir is also used to share data between containers inside a Pod during runtime.

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: emptydir-volume
spec:
  selector:
    matchLabels:
      app: emptydir-volume
  template:
    metadata:
      labels:
        app: emptydir-volume
    spec:
      # add a volume to the deployment
      volumes:
        # mimics a caching memory type
        - name: cache
          # specify the volume type and the temp directory
          emptyDir: {}    
        # of course there could also be a second volume added
      containers:
      - name: container-one
        image: busybox 
        # image used for testing purposes
        # since the testing image immediately dies, we want to
        # execute an own sh command to interact with the volume
        volumeMounts:
        	# The name must match the name of the volume
          - name: cache
          	# interal reference of the pod 
            mountPath: /foo
        command: 
          - "/bin/sh"
        args:
          - "-c"
          - "touch /foo/bar.txt && sleep 3600"
        resources:
          limits:
            memory: "128Mi"
            cpu: "500m"
        # create a second container with a different internal mountPath
      - name: container-two
        image: busybox
        volumeMounts:
          - name: cache
            mountPath: /footwo
        command:
          - "sleep"
          - "3600"
        resources:
          limits:
            memory: "128Mi"
            cpu: "500m"
```

As stated in the yaml, the busybox image immediately dies. If the Containers where created without the shell commands, the pod would be in a crashloopbackoff-state. To prevent the Pod to do so it is caught with the `sleep`commands until it scales down. Accessing a container using `kubectl exec`, it can be checked whether the foo/bar.txt has been created in *container-one*. When checking the second container *container-two*, the same file should be visible as well. This is because both containers refer to the same volume. Keep in mind though that the mountPath of the *container-two* is different.

```bash
# get in container
kubectl exec -it <emptydir-volume-name> -c container-one -- sh
# check whether bar.txt is present
ls

# accessing the second container, there is also a file foo/bar.txt
# remember, both containers share the same volume
kubectl exec -it <emptydir-volume-name> -c container-two -- sh
ls
```

#### HostPath Volume 
THe HostPath Volume type is used when an application needs to access the underlying host file system, meaning the file system of the node. HostPath represents a pre-existing file or directory on the host machine. However, this can be quite dangerous and should be used with caution. If having the right access, the application can interfere and basically mess up the host. It is therefore recommended to set the rights to read only to prevent this from happening. 

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: hostpath-volume
spec:
  selector:
    matchLabels:
      app: hostpath-volume
  template:
    metadata:
      labels:
        app: hostpath-volume
    spec:
      volumes:
        - name: var-log
          # specify the HostPath volume type
          HostPath: {}
          	path: /var/log
      containers:
      - name: container-one
        image: busybox 
        volumeMounts:
	      - name: var-log
	         mountPath: /var/log
        command: 
          - "/bin/sh"
        args:
          # similar to the previous example 
          # create a file and make it sleep
          - "-c"
          - "touch /foo/bar.txt && sleep 3600"
        resources:
          limits:
            memory: "128Mi"
            cpu: "500m"
```

#### Persistent Volumes

Persistent Volumes allow to store data beyond a Pods lifecycle. If a Pod fails, dies or moves to a different node, the data is still intact and can be shared between pods. Persistent Volume types are implemented as plugins that K8s can support(a full list can be found online). Different types of Persistent Volumes are:

+ NFS
+ Local
+ Cloud Network storage (AWS EBS, Azure File Storage, Google Persistent Disk)

The following example show how the usage of Persistent Volumes works on the AWS cloud.
K8s is running on an AWS EKS Cluster and AWS EBS Volumes attached to it. The Container storage interface (CSI) of K8s to use Persistent Volumes is implemented by the EBS provider, e.g. the aws-ebs-plugin. This enables a the use of Persistent Volumes in the EKS cluster. Therefore, a Persistent Volume (PV) is rather the mapping between the storage provider (EBS) and the K8s cluster, than a volume itself. The storage class of a Persistent Volume can be configured to the specific needs. Should the storage be fast or slow, or do we want to have each as a storage? Or might there be other parameters to configure the storage? 

If a Pods or Deployments want to consume storage of the PV, they need to get access to the PV. This is done via a so called persistent volume claim (PVC).

All of this is part of a Persistent Volume Subsystem. The Persistent Volume Subsystem provides an API for users and administrators. The API abstracts details of how storage is provided from how it is consumed. Again, the provisioning of storage is done via a PV and the consumption via a PCV.

<!--- TODO: insert image --->
![Persistent Volume Subsystem](kubernetes_Persistent-Volume-Subsystem.png) 

Listed below are again the three main components when dealing with Persistent Volumes in K8s

+ **Persistent Volume**: is a storage resource provisioned by an administrator
+ **PVC**: is a user's request for and claim to a persistent volume.
+ **Storage Class**: describes the parameters for a class of storage for which PersistentVolumes can be dynamically provisioned.

So how are Persistent Volumes specified in our deployments yamls? As there are `kind:Pod` ressources, there can similarly `kind:PersistentVolume` and `kind:PersistentVolumeClaim` be specified. At first, a PV is created. Second, a PVC is created requesting a certaing amount of storage. This PVC is then linked in the specifications of a Deployment to allow its containers to utilized the storage. The yaml code below shows this process.

```yaml
apiVersion: v1
kind: PersistentVolume
metadata:
  name: mypv
spec:
  # specifiy the capacity of the OV
  capacity:
    storage: "100Mi"
  volumeMode: Filesystem
  accessModes:
    - ReadWriteOnce
  persistentVolumeReclaimPolicy: Recycle
  storageClassName: manual
  hostPath:
  	# specify the hostPath on the node
    path: "/mnt/data"
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: mypvc
spec:
  resources:
    requests:
      storage: "100Mi"
  volumeMode: Filesystem
  storageClassName: "manual"
  accessModes:
    - ReadWriteOnce
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: pv-pvc-deployment
spec:
  selector:
    matchLabels:
      app: pv-pvc
  template:
    metadata:
      labels:
        app: pv-pvc
    spec:
      volumes:
        - name: data
          # efine the use of the PVC by specifying the name
          persistentVolumeClaim:
            claimName: mypvc
      containers:
      - name: pv-pvc
      	# default image
        image: nginx
        volumeMounts:
        	# since the PVC is stated, the container needs to 
          # mount inside it
          - mountPath: "/usr/share/nginx/html"
          	# name is equal to the pvc name specified
            name: data
        resources:
          limits:
            memory: "128Mi"
            cpu: "500m"
        ports:
        - containerPort: 80
---
apiVersion: v1
kind: Service
metadata:
  name: pv-pvc
spec:
  type: LoadBalancer
  selector:
    app: pv-pvc
  ports:
  - port: 80
    targetPort: 80
```


## ConfigMaps

When building software, the same container image should be used for development, testing, staging, and production stage. Thus, container images should be reusable. What usually changes are only the configuration settings of the application. *ConfigMaps* allow to store such configurations as a simple mapping of key-value pairs. Most of the time, the configuration within a config map is injected using environment variables and volumes. However, ConfigMaps should only be used to store configuration files, not sensitive data, as they do not secure them.
Besides allow for an easy change of variables, another benefit of using ConfigMaps is that changes in the configuration are not disruptive, meaning the application can still run while the configuration changes without affecting the application. However, one needs to keep in mind that change made to ConfigMaps and environment variables will not be reflected on already and currently running containers. <!--- TODO: check this --->

The following example creates two different ConfigMaps. The first one includes three environment variables as data. The second one include a more complex configuration of an nginx server.

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: app-properties
data:
  app-name: order
  app-version: 1.0.0
  team: engineering
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: nginx-conf
data:
	# configuration in .conf
  nginx.conf: |
    server {
        listen       80;
        server_name  localhost;

        location / {
            root   /usr/share/nginx/html;
            index  index.html index.htm;
        }

        # redirect server error pages to the static page /50x.html
        #
        error_page   500 502 503 504  /50x.html;
        location = /50x.html {
            root   /usr/share/nginx/html;
        }

        location /health {
            access_log off;
            return 200 "healthy\n";
        }
    }

```

A Deployment is created additionally which uses both ConfigMaps. A ConfigMap is declared under `spec.volumes` as well. It is also possible to state a reference to both ConfigMaps simultaneously. The Deployment creates two containers. The first container mounts each ConfigMap as a Volume. Container two uses environment variables to access and configure the key-value pairs of the ConfigMaps and store them on the container.

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: config-map
spec:
  selector:
    matchLabels:
      app: config-map
  template:
    metadata:
      labels:
        app: config-map
    spec:
      volumes:
      	# specify ConfigMap nginx-conf
        - name: nginx-conf
          configMap:
            name: nginx-conf
        # specify ConfigMap app-properties
        - name: app-properties
          configMap:
            name: app-properties
        # if both configmaps shall be mounted under one directory,
        # we need to use projected
        - name: config
          projected:
            sources:
              - configMap:
                  name: nginx-conf
              - configMap:
                  name: app-properties
      containers:
      - name: config-map-volume
        image: busybox
        volumeMounts:
          - mountPath: /etc/order/ngnix
          # is defined here in the nginx-volume to mount
            name: nginx-conf
          # everything from that configMap is mounted as a file
          # the file content is the value themselves
          - mountPath: /etc/order/properties
            name: app-properties
          - mountPath: etc/order/config
            name: config
        command:
          - "/bin/sh"
          - "-c"
        args:
          - "sleep 3600"
        resources:
          limits:
            memory: "128Mi"
            cpu: "500m"
      - name: config-map-env
        image: busybox
        resources:
          limits:
            memory: "128Mi"
            cpu: "500m"
        # as previously, keep the busybox container alive
        command:
          - "/bin/sh"
          - "-c"
        args:
          - "env && sleep 3600"
        env:
          # environment variables to read in from config map
          # for every data key-value pair in config Map, an own
          # environment variable is created, which gets 
          # the value from the corresponding key
          - name: APP_VERSION
            valueFrom:
              configMapKeyRef:
                name: app-properties
                key: app-version
          - name: APP_NAME
            valueFrom:
              configMapKeyRef:
                name: app-properties
                key: app-name
          - name: TEAM
            valueFrom:
              configMapKeyRef:
                name: app-properties
                key: team
          # reads from second config map
          - name: NGINX_CONF
            valueFrom:
              configMapKeyRef:
                name: nginx-conf
                key: nginx.conf  
```

<!---
config map env

config maps and volumes. One pod is a selection of one or more containers, as well as one or more volumes. The volume is mounted inside the container. Whereever a volume is mounted, we get a file structure like this:

/etc/name
	/app.version
	/server.name

the contents of that file is the values for each key inside of that data.
--->

## Secrets

Secrets, as the name suggests, store and manage sensitive information. However, secrets are actually not secrets in K8s. They can quite easily decoded using `kubectl describe` on a secret and decode it using the shell command `echo <password> | base64 -d`. Thus, sensitive information like database password should never be stored in secrets. There are much better ressources to store such data, for example a Vault on the cloud provider itself.

<!---
Why are we using them in the first place then?
--->

It is possible to create secrets using imperative approach as shown below.

```bash
# create the two secrets db-password and api-token
kubectl create secret generic mysecret --from-literal=db-password=123 -from-literal=api-token=token

# output the new secret as yaml
kubectl get secret mysecret -o yaml

# create a secret from file
kubectl create secret generic mysecret-from-file --from-file=secret
```

<!---
how does the file look?
--->

Similar to ConfigMaps, secrets are accessed via an environment variable or a volume. 

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: secrets
spec:
  selector:
    matchLabels:
      app: secrets
  template:
    metadata:
      labels:
        app: secrets
    spec:
      volumes:
      	# get the secret from a volume
        - name: secret-vol
          secret:
          	# the name of the secret we created earlier
            secretName: mysecret
      containers:
      - name: secrets
        image: busybox
        volumeMounts:
          - mountPath: /etc/secrets
            name: secret-vol
        env:
          # nane of the secret in the container
          - name: CUSTOM_SECRET
    	      # get the secret from an environment variable
            valueFrom:
              secretKeyRef:
              	# name and key of the secret we created earlier
                name: mysecret-from-file
                key: secret
        command:
          - "sleep"
          - "3600"
        resources:
          limits:
            memory: "128Mi"
            cpu: "500m"
```

#### Exemplary use case of secrets

When pulling from a private dockerhub repository, applying the deployment will throw an error since there are no username and password specified. As they should not be coded into the deployment yaml itself, they can be accessed via a secret. In fact, a specific secret can be specified for docker registry. The secret can be specified using the imperative approach.

```bash
kubectl create secret docker-registry docker-hub-private \
--docker-username=YOUR_USERNAME \
--docker-password=YOUR_PASSWORD \
--docker-email=YOUR_EMAIL
```

Finally, the secret is specified in the deployment configuration where it can be accessed during application.

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: secret-app
spec:
  selector:
    matchLabels:
      app: secret-app
  template:
    metadata:
      labels:
        app: secret-app
    spec:
      # specifiy the docker-registry secret to be accessed
      imagePullSecrets:
        - name: docker-hub-private
      containers:
      - name: secret-app
        image: seblum/private
        resources:
          limits:
            memory: "128Mi"
            cpu: "500m"
        ports:
        - containerPort: 80
```


## Health Checks
Applications running in service need to be healthy at all times so they are ready to receive traffic. K8s uses a process called health checks to test whether an application is alive. If there are any issues and the application is unhealthy, K8s will restart the process. Yet, checking only whether a process is up and running might be not sufficient. What if, e.g., a client wants to connect to a database and the connection cannot be established, even though the app is up and running? To solve more specific issues like this, health checks like a *liveness probe* or *readiness probe* can be used. If there have not been specified, K8s will use the default checks to test whether a process is running.

#### Liveness Probe
The Kubelet of a node uses *Liveness Probes* to check whether an application runs fine and whether it can receive traffic. For example, they could catch a deadlock, a database connection failure, etc. Otherwise it will restart a container. To use a Liveness Probe, an endpoint needs to be specified. The benefit of this is, that it is simple to define what it means for an application to be healthy just by defining a path. 
<!---
check again on K8s online
--->

#### Readiness Probe
Similar to a Liveness Probe, the *Readniness Probe* is used by the kubelet to check when the container is ready to start accepting traffic. Its configuration is also done by specifying a path to what it means the application is healthy. A lot of frameworks, like e.g. springboot, actually provide a path to use.
<!---
check again on K8s online
--->

Belows configuration shows a Deployment which includes a Liveness and a Readiness Probe. The image of the deployment is set up so its process is killed after a given number of seconds. This has been passed using environment variables such as seen in the script.

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: customer
  namespace: engineering
spec:
  replicas: 20
  selector:
    matchLabels:
      app: customer
  template:
    metadata:
      labels:
        app: customer
        environment: test
        tier: backend
        department: engineering
    spec:
      containers:
        - name: customer
          image: "amigoscode/kubernetes:customer-v1"
          # check whether I have to change the streamlit app to do this.
          image: "seblum/mlops-public:healthchecks-v1"
          resources:
            limits:
              memory: "128Mi"
              cpu: "500m"
    	    # Specification of the the Liveness Probe
          livenessProbe:
            httpGet:
        	    # path of the url
              path: /health
              port: 8080
            # time the liveness probe starts after pod is started
            initialDelaySeconds: 5
            timeoutSeconds: 1
            failureThreshold: 3
            # period if time when the checks should be performed
            periodSeconds: 5
          # Specification of the Readiness Probe
          readinessProbe:
            httpGet:
              path: /health
              port: 8080
            initialDelaySeconds: 10
            timeoutSeconds: 1
            failureThreshold: 3
            periodSeconds: 5
          env:
          	# variable for the container to be killed after 30 seconds
          	# needs to be implemented within the container though
          	- name: "KILL_IN_SECODS"
          	  value: "30"
            - name: ORDER_SERVICE
              value: "order"
          ports:
            - containerPort: 8080
---
apiVersion: v1
kind: Service
metadata:
  name: customer-node
  namespace: engineering
spec:
  type: NodePort
  selector:
    app: customer
  ports:
    - port: 80
      targetPort: 8080
      nodePort: 30000
---
apiVersion: v1
kind: Service
metadata:
  name: customer
  namespace: engineering
spec:
  type: ClusterIP
  selector:
    app: customer
  ports:
    - port: 80
      targetPort: 8080
```


## Ressource Management

Besides the importance of a healthy application itself, there should be also enough resources allocated so the application can perform well, e.g. memory & CPU. Yet, it should also only consume the resources needed and not block unneeded ones. It might be dangerous, as one application using a lot of ressources, leaving nothing left for other applications and eventually starving them. To prevent this from happening in K8s. there can be a minimum amount of resources defined a container needs (request) as well as the maximum amount of resources a container can have (limit). Configuring limits and requests for a container can be done within the spec for a Pod or Deployment. Actually, we have been using them all the time previously.

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: customer
spec:
  replicas: 2
  selector:
    matchLabels:
      app: customer
  template:
    metadata:
      labels:
        app: customer
    spec:
      containers:
        - name: customer
          image: "amigoscode/kubernetes:customer-v1"
          # allocate the resources needed
          resources:
          	# Requests
          	requests:
          	  memory: "512Mi"
          	  cpu: "1000m"
          	# Limits
            limits:
              memory: "128Mi"
              cpu: "500m"
          ports:
            - containerPort: 8080
```


## Deamon Sets
The master node of K8s decides on what worker nodes a pod is scheduled or not. However, there are times where we want to have a copy of a pod across the cluster. A *DeamonSet* ensures a copy of the specified Pod is exactly doing this. This can be useful for example to deploy system daemons such as log collectors and monitoring agents. DeamonSets are automatically deployed on every single node, unless specified on which node to run. They therefore do not need a specification of nodes and can scale up and down with the cluster as needed. They will automatically scheduled a pod on each new node.

The given example deploys a DaemonSet to cover logging using K8s FluendID.
<!---
why is the voluem attached?
--->

```yaml
apiVersion: v1
kind: Namespace
metadata:
  name: logging
---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: fluentd-elasticsearch
  namespace: logging
  labels:
    k8s-app: fluentd-logging
spec:
  selector:
    matchLabels:
      name: fluentd-elasticsearch
  template:
    metadata:
      labels:
        name: fluentd-elasticsearch
    spec:
      tolerations:
      # this toleration is to have the daemonset runnable on master nodes
      # remove it if your masters can't run pods
      - key: node-role.kubernetes.io/master
        operator: Exists
        effect: NoSchedule
      # specify the containers as done in Pods or Deployments
      volumes:
      - name: varlog
        hostPath:
          path: /var/log
      - name: varlibdockercontainers
        hostPath:
          path: /var/lib/docker/containers
      containers:
      - name: fluentd-elasticsearch
        # allows to collect logs from nodes
        image: quay.io/fluentd_elasticsearch/fluentd:v2.5.2
        resources:
          limits:
            memory: 200Mi
          requests:
            cpu: 100m
            memory: 200Mi
        volumeMounts:
        - name: varlog
          mountPath: /var/log
        - name: varlibdockercontainers
          mountPath: /var/lib/docker/containers
          readOnly: true
      terminationGracePeriodSeconds: 30
```


## StatefulSets
*StatefulSets* are used to deploy and manage stateful applications. Stateful applications are applications which are long lived, for example databases. Most applications of K8s are stateless as they only run for a specific task. However, a database is a state of truth and should be present at all time. StatefulSets manage the pods based on the same container specifications such as Deployments.

Lets assume we have a StatefulSet with 3 replicas. Each Pod has a PV attached.

```yaml
```


## Jobs & Cron Jobs

Using the *busybox* image in the section about volumes we experienced that the image is very short lived. K8s is not aware of this and runs into a CrashLoopBackOff-Error. K8s will try and restart the container itself though until it BackOffs completley. Because the image is so short live, a job within the image has to be executed such as done with a shell command previously. However, what if we have a simple task that only should run like every 5 minutes, or every single day? A good idea is to use CronJobs for such tasks that start the image if needed. When comparingJobs jobs and CronJobs, jobs execute only once, whereas CronJobs execute depending on an specified expression.

The following job simulates a backup to a database that runs 30 seconds in total. The part in the `args` specifies that the container will sleep for 20 seconds (the hypothetical backup). Afterward, the container will wait 10 seconds to shut down, as specified in `ttlSecondsAfterFinished`.
```yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: db-backup-job
spec:
  # time it takes to terminate the job for one completion
  ttlSecondsAfterFinished: 10
  template:
    spec:
      containers:
      - name: backup
        image: busybox
        command: ["/bin/sh", "-c"]
        args:
          - "echo 'performing db backup...' && sleep 20"
      restartPolicy: Never
```

The CronJob below runs run every minute. Given the structure of ( * * * * * * ) - ( Minutes Hours Day-of-month Month Day-of-week Year), the cronjob expression defines as follows:
```yaml
apiVersion: batch/v1beta1
kind: CronJob
metadata:
  name: db-backup-cron-job
spec:
  schedule: "*/1 * * * *"
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - name: backup
            image: busybox
            command: ["/bin/sh", "-c"]
            args:
              - "echo 'performing db backup...' && sleep 20"
          restartPolicy: Never
```