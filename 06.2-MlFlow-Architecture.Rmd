
## MLFflow Architecture

While MLflow can be run locally for your personal model implementation, it is usually deployed on a distributed architecture for large organizations or teams. The MLflow backend consists of three different main components, tracking server, backend store, and artifact store, all of which can reside on remote hosts.

The MLflow client can interface with a variety of backend and artifact storage configurations. The official [MLflow documentation](https://mlflow.org/docs/latest/tracking.html#how-runs-and-artifacts-are-recorded) outlines several detailed configurations. The example below depicts the main interaction between the different architectural components of a remote MLflow Tracking Server, a Postgres database for backend entity storage, and an S3 bucket for artifact storage.

![MLflow Architecture Diagram](images/06-MLflow/MLflow_architecture_diagram.png)


### MLflow Tracking Server

The MLflow *Tracking Server* is the main component that handles the communication between the REST API to log parameters, metrics, experiments and metadata to a storage solution. Further, the Tracking UI allows to view runs on a web interface. Running the CLI command `mlflow ui` starts a web server on your local machine serving the MLFlow UI. Alternatively, the [MLflow tracking server](https://mlflow.org/docs/latest/tracking.html#tracking-server) serves the same UI which can be accessed using the URL `http://<TRACKING-SERVER-IP-ADDRESS>:5000` from any machine that cann connect to the tracking server.

Although it is possible to track parameters without running a server, it is recommended to create a MLflow tracking server to log your data to. Some of the functionality of the API is also available via the web interface, for example to create an experiment. The *Tracking Server* uses both, the backend store and the artifact store to store and read data from. 

### MLflow Backend Store

The MLflow *Backend Store* is where MLflow stores experiment and run metadata like parameters, metrics, and experiments of the runs. It is usually a relational database which means that all metadata will be stored but no large data files.

MLflow supports two types of backend stores: *file store* and *database-backed store*. By default, the backend store is set to the local file store backend at the `./mlruns` directory. A database-backed store must be configures using the `--backend-store-uri`. MLflow supports encoded Databases like *mysql*, *mssql*, *sqlite*, and *postgresql*. To be able to use the *MLflow Model Registry* the server must use a database-backed store.

It is possible to use a variety of externally hosted metadata stores to use as the *Backend Store*, for example MySQL, or AWS RDS


### MLflow Artifact Store

The MLflow *Artifact Store* is a location to store large data of an ML run that are not suitable for a relational database. This is where MLflow users log their artifact output, or data and image files to. In addition to the Backend store it is another storage place for the MLflow tracking server.  A user can access artifacts via HTTP requests to the MLflow Tracking Server. 

The location to the server’s artifact store defaults to local `./mlruns` directory. It is possible to specify another artifact store server using `--default-artifact-root`. The MLflow client caches the artifact location information on a per-run basis. It is therefore not recommended to alter a run’s artifact location before it has terminated.

The *Artifact Store* needs to be configured when running MLflow on a distributed system. In addition to local file paths, MLflow supports to configure the following cloud storage resources as an artifact stores: Amazon S3, Azure Blob Storage, Google Cloud Storage, SFTP server, and NFS.
